{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 1 — Rao–Blackwell Theorem\n",
        "\n",
        "Let $X_1, \\dots, X_n \\sim \\text{Poisson}(\\lambda)$ with unknown $\\lambda>0$.\n",
        "\n",
        "We define a deliberately inefficient unbiased estimator:\n",
        "$$\n",
        "\\hat{\\lambda}_0 = \\frac{1}{n}\\sum_{i=1}^n \\big( X_i - \\mathbf{1}_{\\{X_i=0\\}} \\big).\n",
        "$$\n",
        "\n",
        "We know that $S=\\sum_i X_i$ is a **sufficient statistic** for $\\lambda$.\n",
        "\n",
        "---\n",
        "\n",
        "1. Simulate $N=2\\times10^5$ Poisson samples.  \n",
        "2. Compute $\\hat{\\lambda}_0$ and $S$.  \n",
        "3. Approximate $\\mathbb{E}[\\hat{\\lambda}_0\\mid S]$ numerically by local averaging.  \n",
        "4. Compare empirical variances of $\\hat{\\lambda}_0$ and its Rao–Blackwellized version $\\hat{\\lambda}^*(S)=\\mathbb{E}[\\hat{\\lambda}_0\\mid S]$."
      ],
      "metadata": {
        "id": "-ZKx6tSYCZ0-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 2 — Numerical verification of completeness\n",
        "\n",
        "Let $S\\sim \\mathrm{Binomial}(n,p)$ and suppose $\\varphi:\\{0,1,\\dots,n\\}\\to\\mathbb{R}$.\n",
        "Completeness means:\n",
        "$$\n",
        "E_p[\\varphi(S)] = \\sum_{s=0}^n \\varphi(s)\\,P_p(S=s) = 0 \\quad\\text{for all } p\\in(0,1)\n",
        "\\quad\\Longrightarrow\\quad \\varphi(s)=0\\ \\text{for all } s.\n",
        "$$\n",
        "\n",
        "To verify this numerically we discretize the continuum of $p$ values by a grid $p_1,\\dots,p_m$.\n",
        "Define the matrix $M\\in\\mathbb{R}^{m\\times (n+1)}$ by\n",
        "$$\n",
        "M_{i,s} \\;=\\; P_{p_i}(S=s),\\qquad i=1,\\dots,m,\\ \\ s=0,\\dots,n.\n",
        "$$\n",
        "\n",
        "If a vector $\\varphi=(\\varphi(0),\\dots,\\varphi(n))^\\top$ satisfies\n",
        "$$\n",
        "M\\,\\varphi = 0,\n",
        "$$\n",
        "then for each $p_i$ we have $E_{p_i}[\\varphi(S)]=0$. If $M$ has full column rank (rank $=n+1$), then the only solution is $\\varphi=0$, and this provides a numerical certificate that no nontrivial function $\\varphi$ has expectation zero on the chosen grid of $p$'s. With a dense enough grid this gives strong evidence of completeness.\n",
        "\n",
        "**Important numerical remarks**\n",
        "- For the test to be meaningful choose $m\\ge n+1$ and distinct $p_i$ values.  \n",
        "- Rank deficiencies (near-zero singular values) indicate possible non-uniqueness or numerical ill-conditioning — increase the grid, change spacing, or increase numerical precision.\n",
        "- This is a **numerical** test, not a proof; but for classical families (Binomial, Poisson) it confirms the theoretical completeness.\n"
      ],
      "metadata": {
        "id": "mlvfc2daD4He"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 3 — MVUE for θ = e^{-λ} in the Poisson model\n",
        "\n",
        "Let $X_1,\\dots,X_n\\overset{\\text{i.i.d.}}{\\sim}\\mathrm{Poisson}(\\lambda)$.\n",
        "We want an estimator for $\\theta := e^{-\\lambda}$.\n",
        "Theoretically, the estimator $\\hat\\theta_0=\\mathbf{1}\\{X_1=0\\}$ is unbiased for $\\theta$.  \n",
        "\n",
        "1. Compute the Rao–Blackwellized estimator $\\hat\\theta^*(S)=\\mathbb{E}[\\hat\\theta_0\\mid S]$ as a function of $S=\\sum_i X_i$. (Hint: conditional on $S=s$ the joint cell counts follow a multinomial with equal cell-probabilities.)  \n",
        "2. Simulate many samples (e.g. $N=2\\cdot 10^5$), compute $\\hat\\theta_0$ and $\\hat\\theta^*(S)$, and verify:\n",
        "   - both are unbiased (empirically),\n",
        "   - $\\operatorname{Var}(\\hat\\theta^*) < \\operatorname{Var}(\\hat\\theta_0)$.\n",
        "3. Print empirical MSEs and show a short table for several $\\lambda$ values."
      ],
      "metadata": {
        "id": "tblLunp7EePY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 4 — Uniqueness of MVUE from completeness (Bernoulli case)\n",
        "\n",
        "Let $X_1,\\dots,X_n\\overset{\\text{i.i.d.}}{\\sim}\\mathrm{Bernoulli}(p)$ and $S=\\sum_i X_i\\sim\\mathrm{Binomial}(n,p)$.\n",
        "We know $S$ is sufficient and complete. The Lehmann–Scheffé theorem implies that the MVUE that is $S$-measurable is unique.\n",
        "\n",
        "Numerically demonstrate uniqueness as follows:\n",
        "\n",
        "1. Let $\\hat p_{\\text{RB}}(S)=S/n$ be the Rao–Blackwellized estimator of $p$.  \n",
        "2. Suppose $\\psi$ is any estimator that depends on $S$ only; write its values as the vector $a=(a_0,\\dots,a_n)$ where $\\psi(S=s)=a_s$.  \n",
        "3. Unbiasedness demands $E_p[\\psi(S)]=p$ for every $p$. Discretize and enforce the condition for several $p$ grid points to obtain a linear system $M a \\approx b$ (where $b$ contains the values $p_i$).  \n",
        "4. Solve for $a$ (least squares) and compare the solution to $a_s=s/n$. Show numerically that the solution equals $s/n$ (up to numerical error), illustrating uniqueness."
      ],
      "metadata": {
        "id": "wWnejnv2GSad"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 5 — MVUE for the rate of an exponential and numerical comparison\n",
        "\n",
        "Let $X_1,\\dots,X_n$ be i.i.d. Exponential with *rate* $\\lambda>0$, i.e.\n",
        "$$\n",
        "f(x;\\lambda)=\\lambda e^{-\\lambda x},\\quad x>0.\n",
        "$$\n",
        "Equivalently the mean is $\\theta=1/\\lambda$ and $S=\\sum_{i=1}^n X_i\\sim\\mathrm{Gamma}(n,\\ \\text{rate}=\\lambda)$.\n",
        "\n",
        "We are interested in estimating the *rate* $\\lambda$.\n",
        "\n",
        "**Analytic part (seminar):**\n",
        "1. Show that\n",
        "   $$\n",
        "   \\widehat\\lambda_{\\text{MVUE}}=\\frac{n-1}{S}\n",
        "   $$\n",
        "   is unbiased for $\\lambda$ (hint: use $E[1/S]$ for a Gamma random variable).\n",
        "2. Recall the Cramér–Rao lower bound (CRLB) for unbiased estimators of $\\lambda$ in this model:\n",
        "   $$I_n(\\lambda)=\\frac{n}{\\lambda^2}\\quad\\Longrightarrow\\quad \\operatorname{Var}(\\text{any unbiased estimator})\\ge \\frac{\\lambda^2}{n}.$$\n",
        "\n",
        "**Numerical part:**\n",
        "3. For fixed true $\\lambda$ (take $\\lambda=2.0$) and for $n\\in\\{5,10,25,50,100\\}$:\n",
        "   - Simulate $N=200{,}000$ Monte Carlo samples of size $n$.\n",
        "   - For each replication compute:\n",
        "     * the MVUE $\\widehat\\lambda_{\\text{MVUE}}=(n-1)/S$,\n",
        "     * the plug-in estimator $\\widehat\\lambda_{\\text{MLE}}=1/\\overline X = n/S$ (MLE, biased),\n",
        "     * the bias, variance and MSE of both estimators.\n",
        "   - Estimate the empirical ratio\n",
        "     $$\n",
        "     R_n:=\\frac{n\\cdot\\operatorname{Var}(\\widehat\\lambda_{\\text{MVUE}})}{\\lambda^2},\n",
        "     $$\n",
        "     and check whether $R_n\\to 1$ as $n$ grows (numerical check of asymptotic efficiency).\n",
        "4. Use a nonparametric bootstrap (B=2000 resamples) to estimate the variance of $\\widehat\\lambda_{\\text{MVUE}}$ at $n=25$ and compare the bootstrap estimate to the empirical Monte Carlo variance.\n",
        "5. Produce a short report (table + 2 plots):\n",
        "   - Table with columns: $n$, empirical bias(MVUE), var(MVUE), MSE(MVUE), bias(MLE), var(MLE), MSE(MLE), $R_n$.\n",
        "   - Plot 1: var(MVUE) and var(MLE) vs $n$ (log-scale on y-axis).\n",
        "   - Plot 2: $R_n$ vs $n$ with a horizontal line at 1.\n"
      ],
      "metadata": {
        "id": "73EsTHESH0Lt"
      }
    }
  ]
}